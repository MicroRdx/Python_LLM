{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI as LangchainOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize OpenAI client (Optional: Only needed if you use OpenAI API directly)\n",
    "openai_client = OpenAI(\n",
    "    api_key=\"your-api-key-here\",  # Replace with your actual OpenAI API key\n",
    "    organization=\"your-org-id\"    # Optional: Include your organization ID if applicable\n",
    ")\n",
    "\n",
    "def generate_question_from_document(document_content, question_instruction):\n",
    "    \"\"\"\n",
    "    Generates a question based on the provided document content using LLM.\n",
    "    \n",
    "    Args:\n",
    "        document_content (str): The content extracted from the student's document.\n",
    "        question_instruction (str): Instructions for generating a relevant question.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated question as a response from the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the prompt template with placeholders for content and instruction\n",
    "    prompt_template = \"\"\"\n",
    "    Document Content: {document_content}\n",
    "    Instruction: {question_instruction}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a PromptTemplate instance with the defined template\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template, \n",
    "        input_variables=['document_content', 'question_instruction']\n",
    "    )\n",
    "    \n",
    "    # Initialize the OpenAI model through Langchain\n",
    "    llm = LangchainOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",         # Using GPT-3.5-turbo model\n",
    "        temperature=0.3,                    # Temperature set to 0.3 for balanced creativity and precision\n",
    "        openai_api_key=\"your-api-key-here\"   # Replace with your actual OpenAI API key\n",
    "    )\n",
    "    \n",
    "    # Create the LLMChain with the prompt and the model\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    \n",
    "    # Invoke the chain with the content and question instruction\n",
    "    response = llm_chain.invoke({\n",
    "        'document_content': document_content,\n",
    "        'question_instruction': question_instruction\n",
    "    })\n",
    "    \n",
    "    # Return the generated question from the response\n",
    "    return response['text'].strip()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample document content from student's submission (can be extracted using libraries like PyPDF2, pdfplumber, etc.)\n",
    "    sample_document_content = \"Blockchain technology has the potential to revolutionize industries by providing decentralized, secure, and transparent transactions.\"\n",
    "    \n",
    "    # Instruction for generating a question\n",
    "    question_instruction = \"Generate a single, concise question based on the above content.\"\n",
    "    \n",
    "    # Generate a question from the document content\n",
    "    generated_question = generate_question_from_document(sample_document_content, question_instruction)\n",
    "    \n",
    "    # Output the generated question\n",
    "    print(\"Generated Question:\", generated_question)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
